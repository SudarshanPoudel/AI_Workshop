{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73664688",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "## Step 1. Read dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/insurance.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ef1cd",
   "metadata": {},
   "source": [
    "In this notebook we'll be using insurance charges dataset, as we can see dataset contains various features (`age, sex, bmi, no. of childrens, smoker status and region`) with target `charges`. Our main goal is to train a ML model that takes new person's features and predicts the estimated insurance charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58332d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Let's take a look at the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=5) # Instead of .head we can use .sample() to see random n rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d29b4",
   "metadata": {},
   "source": [
    "## Step 2. Simple Preprocessing\n",
    "\n",
    "Before we build any model, we should quickly check the quality of our data.\n",
    "\n",
    "In this step, we will:\n",
    "- Look for **missing (null) values**\n",
    "- Check if there are any **duplicate rows**\n",
    "\n",
    "These are common issues in real-world datasets and are usually handled early in the ML workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d9913",
   "metadata": {},
   "source": [
    "As we see there are no null values, but 1 duplicated row.\n",
    "\n",
    "There are various ways of handeling null values. Simplest solution is to drop them, however of large amount of rows contains null, we may need to infer it using various statistic based estimattions (Putting mean, medion, mod etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6eb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f344c5",
   "metadata": {},
   "source": [
    "## Step 3. Visualization\n",
    "\n",
    "Next step is to visualize and analze various columns of our dataset, we'll see their distributation, corelations and do comparisions.\n",
    "For this we'll use matplotlib library.\n",
    "\n",
    "Let's start by analizing our target column (dependent variable), in this case Insurance charges. Since this is continious data, we can use histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c39891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df[\"charges\"], bins=100)\n",
    "plt.xlabel(\"Insurance Charges\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Insurance Charges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45647cf0",
   "metadata": {},
   "source": [
    "From the distribution, we can see that there are some data points with very high insurance charges. These values may be outliers. One common way to identify outliers is by visualizing the data using a box plot.\n",
    "\n",
    "Outliers can cause issues for some machine learning models, so they often need to be handled carefully. However, in this example, we will keep them for simplicity.\n",
    "\n",
    "There are three common ways to handle outliers:\n",
    "1. Dropping them\n",
    "2. Capping (limiting extreme values)\n",
    "3. Changing the scale of the data (e.g., using a log transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.boxplot(column=\"charges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378ca67",
   "metadata": {},
   "source": [
    "### Bivarient analysis\n",
    "Next let's visualize and see how each features affects insurance charges using varios plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83537c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df[\"age\"], df[\"charges\"], alpha=0.5)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"Age vs Insurance Charges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c07bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df[\"bmi\"], df[\"charges\"], alpha=0.5)\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"BMI vs Insurance Charges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e30947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.boxplot(column=\"charges\", by=\"smoker\")\n",
    "plt.xlabel(\"Smoker\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"Charges by Smoking Status\")\n",
    "plt.suptitle(\"\")  # remove auto title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.boxplot(column=\"charges\", by=\"sex\")\n",
    "plt.xlabel(\"Sex\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"Charges by Sex\")\n",
    "plt.suptitle(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.boxplot(column=\"charges\", by=\"region\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"Charges by Region\")\n",
    "plt.suptitle(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa7867",
   "metadata": {},
   "source": [
    "## Step 4. Preprocessing\n",
    "Based on our analysis, we'll them perform proper preprocessing steps. This step may include\n",
    "1. Dropping unnecessary columns\n",
    "2. Handeling outliers\n",
    "3. Mapping categorical data into numeric ones using various encoding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9716617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"region\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b690e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"smoker\"] = df[\"smoker\"].map({\"yes\": 1, \"no\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"sex\"],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex_female\"] = df[\"sex_female\"].astype(int)\n",
    "df[\"sex_male\"] = df[\"sex_male\"].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c937f53",
   "metadata": {},
   "source": [
    "## Step 5. Train test split\n",
    "Once our data is ready, we'll get into model training step. But if we train our model on our entire dataset, how do we later test how good our model is ? How do we test if it overfitted or underfitted ? We need some way to measure our progress, so we'll split our dataset in train and test set.\n",
    "We can then train it on train set and test it on test set that doen't contain any training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"charges\", axis=1)\n",
    "y = df[\"charges\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total length: {len(X)}, Traininig: {len(X_train)}, Testing: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05331d5d",
   "metadata": {},
   "source": [
    "## Step 6. Model training\n",
    "Since target column is numeric value, it is a regression problem. We'll train a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train) # Train a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) # Make predictions on test set\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Actual\": y_test.values,\n",
    "    \"Predicted\": y_pred,\n",
    "    \"Difference\": y_test.values - y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847af6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e652988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(comparison_df[\"Actual\"], comparison_df[\"Predicted\"], alpha=0.5)\n",
    "plt.plot(\n",
    "    [comparison_df[\"Actual\"].min(), comparison_df[\"Actual\"].max()],\n",
    "    [comparison_df[\"Actual\"].min(), comparison_df[\"Actual\"].max()]\n",
    ")\n",
    "plt.xlabel(\"Actual Charges\")\n",
    "plt.ylabel(\"Predicted Charges\")\n",
    "plt.title(\"Actual vs Predicted on Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195c196",
   "metadata": {},
   "source": [
    "## Step 7. Model evaluation\n",
    "Let's evaluate our model using r2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92332a9",
   "metadata": {},
   "source": [
    "## Step 8. Inference\n",
    "\n",
    "Once we're satisfied with our model, we need a way to serve it. This is called inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame([{\n",
    "    \"age\": 21,\n",
    "    \"bmi\":40.0,\n",
    "    \"children\": 0,\n",
    "    \"smoker\": 0,\n",
    "    \"sex_female\": 0,\n",
    "    \"sex_male\": 1,\n",
    "}])\n",
    "\n",
    "response = model.predict(sample_df)\n",
    "print(f\"Prediction for given sample is : {response[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pred_value = response[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df[\"bmi\"], df[\"charges\"], alpha=0.4, label=\"Training data\")\n",
    "\n",
    "plt.scatter(\n",
    "    sample_df[\"bmi\"],\n",
    "    pred_value,\n",
    "    color=\"red\",\n",
    "    s=120,\n",
    "    label=\"Our prediction\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Insurance Charges\")\n",
    "plt.title(\"Model Prediction in Context of Data\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6611ca1",
   "metadata": {},
   "source": [
    "## Save our model\n",
    "\n",
    "Currently our ai model is inside `model` object. We need to save it somewhere, otherwise each time we need to train it every time we use it, which is not possible. We can use simple library like joblib to save our python object as .pkl file, and later recreate exact model using that file without loosing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae515ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"../models/regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bef0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use that .pkl file to create simple prediction system\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "ai_model = joblib.load(\"../models/regression_model.pkl\")\n",
    "\n",
    "def predict_insurance(\n",
    "    age: int,\n",
    "    bmi: float,\n",
    "    children: int,\n",
    "    smoker: bool,\n",
    "    sex: Literal[\"male\", \"female\"]\n",
    "):  \n",
    "    sample_df = pd.DataFrame([{\n",
    "        \"age\": age,\n",
    "        \"bmi\":bmi,\n",
    "        \"children\": children,\n",
    "        \"smoker\": 1 if smoker else 0,\n",
    "        \"sex_female\": 1 if sex==\"female\" else 0,\n",
    "        \"sex_male\": 1 if sex==\"male\" else 0,\n",
    "    }])\n",
    "    response = ai_model.predict(sample_df)\n",
    "\n",
    "    cost = float(response[0])\n",
    "    return round(cost, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_insurance(age=23, bmi=31.1, children=1, smoker=False, sex=\"male\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
